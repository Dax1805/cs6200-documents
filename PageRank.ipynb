{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PageRank.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Dax1805/cs6200-documents/blob/main/PageRank.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q2QKFIlR6HCY"
      },
      "source": [
        "# PageRank\n",
        "\n",
        "In this exercise, you will compute PageRank on a collection of 469,235 web sites using the iterative version of the PageRank algorithm described in class for sparse graphs.  As we discussed in class, this avoids performing cubic-time operations on a graph with a large number of nodes.\n",
        "\n",
        "Furthermore, you should take advantage of the _sparsity_ of the original hyperlinks, even though \"teleportation\" or random jumps connect every note to every other node.  As long as the maximum degree of the original link graph is much less than the number of nodes, you should be able to keep each iteration's runtime less than quadratic in the number of nodes.\n",
        "\n",
        "Consider the following directed graph:\n",
        "\n",
        "![A directed link graph](https://www.khoury.northeastern.edu/home/dasmith/courses/cs6200//pagerank.jpg)\n",
        "\n",
        "We can represent this graph as a collection of nodes, here, ordered pairs of node index and node name:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4D_Mxj5pXKPl"
      },
      "source": [
        "small_nodes = [(0, 'A'),\n",
        "              (1, 'B'),\n",
        "              (2, 'C'),\n",
        "              (3, 'D'),\n",
        "              (4, 'E'),\n",
        "              (5, 'F')]"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RTF3JKtTYxiZ"
      },
      "source": [
        "and a collection of directed links, i.e., ordered pairs from source to target:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-i0V5ueOYDDN"
      },
      "source": [
        "small_edges = [\n",
        "  (0, 1),\n",
        "  (0, 2),\n",
        "  (0, 5),\n",
        "  (1, 2),\n",
        "  (1, 3),\n",
        "  (1, 4),\n",
        "  (1, 5),\n",
        "  (2, 3),\n",
        "  (2, 4),\n",
        "  (3, 0),\n",
        "  (3, 2),\n",
        "  (3, 4),\n",
        "  (3, 5),\n",
        "  (4, 0),\n",
        "  (5, 0),\n",
        "  (5, 1),\n",
        "  (5, 4)\n",
        "]"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kBVDeszXY4B_"
      },
      "source": [
        "We use integer identifiers for the nodes for efficiency. In most real-world collections of hyperlinks, unlike this example, not every page will have in-links, nor will every page have out-links."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QPNsTGSsEwMX"
      },
      "source": [
        "## First Implementation and Test\n",
        "\n",
        "\\[10 points\\] Implement the iterative PageRank algorithm we discussed in class. Test your code on the six-node example using the input representation given above.  Be sure that your code handles pages that have no in-links or out-links properly.  (You may wish to test on a few such examples.) In later parts of this assignment, depending on how you store the data, it may be convenient to use iterators rather than storing the data in memory."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NMu_WaDA55sk",
        "outputId": "92b44e27-d0ff-4de2-e48e-7a9788f9ed50",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# TODO: Implement PageRank, given nodes and edges, to start with a uniform\n",
        "# distribution over nodes, run a fixed number of iterations, and\n",
        "# return a distribution over nodes.\n",
        "\n",
        "def page_rank_fixed_iter(nodes, edges, iterations=10, d=0.85):\n",
        "    n = len(nodes)\n",
        "    pr = {node_id: 1.0 / n for node_id, _ in nodes}\n",
        "\n",
        "    outlinks = {node_id: [] for node_id, _ in nodes}\n",
        "    out_degree = {node_id: 0 for node_id, _ in nodes}\n",
        "    for src, dst in edges:\n",
        "        outlinks[src].append(dst)\n",
        "        out_degree[src] += 1\n",
        "\n",
        "    for _ in range(iterations):\n",
        "        new_pr = {node_id: (1 - d) / n for node_id, _ in nodes}\n",
        "        for node_id, rank in pr.items():\n",
        "            if out_degree[node_id]:\n",
        "                share = rank / out_degree[node_id]\n",
        "                for target in outlinks[node_id]:\n",
        "                    new_pr[target] += d * share\n",
        "            else:\n",
        "                share = rank / n\n",
        "                for target in new_pr:\n",
        "                    new_pr[target] += d * share\n",
        "        pr = new_pr\n",
        "\n",
        "    return pr\n",
        "\n",
        "# Output PageRank on the toy graph at various points.\n",
        "# Make sure your output has node number, name, and PageRank value.\n",
        "print(page_rank_fixed_iter(small_nodes, small_edges, 1))\n",
        "print(page_rank_fixed_iter(small_nodes, small_edges, 10))\n",
        "print(page_rank_fixed_iter(small_nodes, small_edges, 100))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{0: 0.24930555555555556, 1: 0.11944444444444445, 2: 0.14305555555555555, 3: 0.13125, 4: 0.2138888888888889, 5: 0.14305555555555555}\n",
            "{0: 0.25203637602817186, 1: 0.1393065091825108, 2: 0.15129376593475072, 3: 0.11896297277689881, 4: 0.18710661014291716, 5: 0.15129376593475072}\n",
            "{0: 0.2521271053751956, 1: 0.1393061853185386, 2: 0.1513064898667053, 3: 0.11890782257353921, 4: 0.1870459069993161, 5: 0.1513064898667053}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y4duRjzABB9n"
      },
      "source": [
        "## PageRank on Web Crawl Data\n",
        "\n",
        "\\[20 points\\] Download and unpack a list of `.edu` websites and the links among them from the [Common Crawl](https://commoncrawl.org/2017/05/hostgraph-2017-feb-mar-apr-crawls/) open-source web crawl. For the sake of brevity, the data record links among websites, not web pages. The information for nodes and links is the same as the toy example above."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v6EDDdTQCd3y",
        "outputId": "1e41aff5-2b3a-40ce-91be-3e7bed0061e0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# If you're running on a machine (e.g., Windows) that doesn't have wget or gzip,\n",
        "# feel free to comment this out and use a different set of commands to load\n",
        "# the data.\n",
        "!wget https://khoury.northeastern.edu/home/dasmith/courses/cs6200/vertices-edu.txt.gz\n",
        "!gzip -df vertices-edu.txt.gz\n",
        "!wget https://khoury.northeastern.edu/home/dasmith/courses/cs6200/edges-edu.txt.gz\n",
        "!gzip -df edges-edu.txt.gz"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-02-22 22:06:41--  https://khoury.northeastern.edu/home/dasmith/courses/cs6200/vertices-edu.txt.gz\n",
            "Resolving khoury.northeastern.edu (khoury.northeastern.edu)... 52.70.229.197\n",
            "Connecting to khoury.northeastern.edu (khoury.northeastern.edu)|52.70.229.197|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 3703486 (3.5M) [application/x-gzip]\n",
            "Saving to: ‘vertices-edu.txt.gz’\n",
            "\n",
            "vertices-edu.txt.gz 100%[===================>]   3.53M  5.49MB/s    in 0.6s    \n",
            "\n",
            "2025-02-22 22:06:42 (5.49 MB/s) - ‘vertices-edu.txt.gz’ saved [3703486/3703486]\n",
            "\n",
            "--2025-02-22 22:06:42--  https://khoury.northeastern.edu/home/dasmith/courses/cs6200/edges-edu.txt.gz\n",
            "Resolving khoury.northeastern.edu (khoury.northeastern.edu)... 52.70.229.197\n",
            "Connecting to khoury.northeastern.edu (khoury.northeastern.edu)|52.70.229.197|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 12829526 (12M) [application/x-gzip]\n",
            "Saving to: ‘edges-edu.txt.gz’\n",
            "\n",
            "edges-edu.txt.gz    100%[===================>]  12.23M  14.0MB/s    in 0.9s    \n",
            "\n",
            "2025-02-22 22:06:44 (14.0 MB/s) - ‘edges-edu.txt.gz’ saved [12829526/12829526]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CW4yp1gPUwzb"
      },
      "source": [
        "There should now be files `vertices-edu.txt` and `edges-edu.txt`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ly1t9fyjK7eC",
        "outputId": "710b41c1-e7b4-45c1-fd10-1d8ce3ad6990",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# TODO: Process the raw data into the same format as the simple graph.\n",
        "# You may create lists or iterators.\n",
        "\n",
        "nodes = []\n",
        "with open('vertices-edu.txt', 'r') as f:\n",
        "    for line in f:\n",
        "        parts = line.strip().split()\n",
        "        if len(parts) < 2:\n",
        "            continue\n",
        "        node_id = int(parts[0])\n",
        "        node_name = \" \".join(parts[1:])\n",
        "        nodes.append((node_id, node_name))\n",
        "\n",
        "edges = []\n",
        "with open('edges-edu.txt', 'r') as f:\n",
        "    for line in f:\n",
        "        parts = line.strip().split()\n",
        "        if len(parts) < 2:\n",
        "            continue\n",
        "        src = int(parts[0])\n",
        "        dst = int(parts[1])\n",
        "        edges.append((src, dst))\n",
        "\n",
        "print(\"Total number of nodes:\", len(nodes))\n",
        "print(\"Total number of edges:\", len(edges))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total number of nodes: 469235\n",
            "Total number of edges: 3300462\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0WMf5L5VEqZb"
      },
      "source": [
        "Refine your implementation of PageRank to test for numerical convergence. Specificially, at each iteration, calculate the [perplexity](https://en.wikipedia.org/wiki/Perplexity) of the PageRank distribution, where perplexity is defined as 2 raised to the [Shannon entropy](https://en.wikipedia.org/wiki/Entropy_(information_theory)) of the PageRank distribution, i.e., $2^{H(PR)}$. (Recall the definition of entropy from our discussion of data compression.) The maximum perplexity of a PageRank distribution will therefore be the number of nodes in the graph.\n",
        "\n",
        "At each iteration, check the _change_ in perplexity. If the change is less than some threshold, you can stop.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wsL0yQKvKqAC",
        "outputId": "20f797dc-99a1-431f-a135-6354fa14083e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# TODO: Implement convergence testing in PageRank\n",
        "# If you choose, you can share some subroutines with your first version.\n",
        "# Print the change in perplexity at each iteration.\n",
        "\n",
        "import math\n",
        "\n",
        "def page_rank(nodes, edges, threshold=1, d=0.85):\n",
        "    n = len(nodes)\n",
        "    pr = {node: 1.0 / n for node, _ in nodes}\n",
        "\n",
        "    outlinks = {node: [] for node, _ in nodes}\n",
        "    out_degree = {node: 0 for node, _ in nodes}\n",
        "    for src, dst in edges:\n",
        "        outlinks[src].append(dst)\n",
        "        out_degree[src] += 1\n",
        "\n",
        "    def perplexity(pr_dist):\n",
        "        entropy = -sum(p * math.log(p, 2) for p in pr_dist.values() if p > 0)\n",
        "        return 2 ** entropy\n",
        "\n",
        "    prev_perp = None\n",
        "    iter_count = 0\n",
        "\n",
        "    while True:\n",
        "        iter_count += 1\n",
        "        # Total PageRank from sink node\n",
        "        sink_total = sum(pr[node] for node in pr if out_degree[node] == 0)\n",
        "        # Base contribution: teleportation plus sink distribution.\n",
        "        new_pr = {node: (1 - d) / n + d * (sink_total / n) for node, _ in nodes}\n",
        "        # Distribute PageRank from non-sink nodes.\n",
        "        for node in pr:\n",
        "            if out_degree[node]:\n",
        "                share = pr[node] / out_degree[node]\n",
        "                for target in outlinks[node]:\n",
        "                    new_pr[target] += d * share\n",
        "\n",
        "        pr = new_pr\n",
        "        cur_perp = perplexity(pr)\n",
        "        change = abs(cur_perp - prev_perp) if prev_perp is not None else None\n",
        "        if change is not None:\n",
        "            print(f\"Iteration {iter_count}: Perplexity = {cur_perp:.6f}, Change = {change:.6f}\")\n",
        "            if change < threshold:\n",
        "                break\n",
        "        else:\n",
        "            print(f\"Iteration {iter_count}: Perplexity = {cur_perp:.6f}\")\n",
        "        prev_perp = cur_perp\n",
        "\n",
        "    return pr\n",
        "# Run until perplexity changes by less than 1\n",
        "PR = page_rank(nodes, edges, 1)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 1: Perplexity = 298071.446167\n",
            "Iteration 2: Perplexity = 255742.814745, Change = 42328.631423\n",
            "Iteration 3: Perplexity = 234252.272154, Change = 21490.542590\n",
            "Iteration 4: Perplexity = 225975.955895, Change = 8276.316259\n",
            "Iteration 5: Perplexity = 221538.999751, Change = 4436.956144\n",
            "Iteration 6: Perplexity = 219533.964586, Change = 2005.035165\n",
            "Iteration 7: Perplexity = 218300.922517, Change = 1233.042069\n",
            "Iteration 8: Perplexity = 217671.939029, Change = 628.983488\n",
            "Iteration 9: Perplexity = 217238.014611, Change = 433.924418\n",
            "Iteration 10: Perplexity = 216999.383617, Change = 238.630994\n",
            "Iteration 11: Perplexity = 216815.233264, Change = 184.150353\n",
            "Iteration 12: Perplexity = 216708.529683, Change = 106.703581\n",
            "Iteration 13: Perplexity = 216619.067759, Change = 89.461924\n",
            "Iteration 14: Perplexity = 216564.521951, Change = 54.545808\n",
            "Iteration 15: Perplexity = 216516.228208, Change = 48.293743\n",
            "Iteration 16: Perplexity = 216485.351334, Change = 30.876874\n",
            "Iteration 17: Perplexity = 216457.057573, Change = 28.293761\n",
            "Iteration 18: Perplexity = 216438.189953, Change = 18.867620\n",
            "Iteration 19: Perplexity = 216420.596688, Change = 17.593265\n",
            "Iteration 20: Perplexity = 216408.425761, Change = 12.170927\n",
            "Iteration 21: Perplexity = 216397.005362, Change = 11.420399\n",
            "Iteration 22: Perplexity = 216388.861965, Change = 8.143397\n",
            "Iteration 23: Perplexity = 216381.220074, Change = 7.641891\n",
            "Iteration 24: Perplexity = 216375.637293, Change = 5.582781\n",
            "Iteration 25: Perplexity = 216370.414746, Change = 5.222547\n",
            "Iteration 26: Perplexity = 216366.525648, Change = 3.889097\n",
            "Iteration 27: Perplexity = 216362.903478, Change = 3.622170\n",
            "Iteration 28: Perplexity = 216360.165319, Change = 2.738159\n",
            "Iteration 29: Perplexity = 216357.626932, Change = 2.538387\n",
            "Iteration 30: Perplexity = 216355.685311, Change = 1.941621\n",
            "Iteration 31: Perplexity = 216353.893286, Change = 1.792025\n",
            "Iteration 32: Perplexity = 216352.509815, Change = 1.383472\n",
            "Iteration 33: Perplexity = 216351.237959, Change = 1.271856\n",
            "Iteration 34: Perplexity = 216350.248849, Change = 0.989110\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rcncY2QHNl0M"
      },
      "source": [
        "## Link Analysis\n",
        "\n",
        "\\[20 points\\] In this final section, you will compute some properties of this web-site graph.\n",
        "\n",
        "First, consider the _in-link count_ of a website, simply the number of websites pointing to it (including self-links)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a_FyPlLSO2bu",
        "outputId": "3716d4e7-6bca-4591-cde3-7c59002cc6e1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# TODO: List the document ID, domain name, and in-link count of the 70 websites with the highest in-link count\n",
        "\n",
        "in_link_counts = {node_id: 0 for node_id, _ in nodes}\n",
        "for src, dst in edges:\n",
        "    in_link_counts[dst] += 1\n",
        "\n",
        "# Combine node information with the in-link counts.\n",
        "node_inlinks = [(node_id, domain, in_link_counts[node_id]) for node_id, domain in nodes]\n",
        "\n",
        "# Sort the nodes in descending order by in-link count.\n",
        "top_70 = sorted(node_inlinks, key=lambda x: x[2], reverse=True)[:70]\n",
        "\n",
        "print(\"Document ID, Domain Name, In-Link Count\")\n",
        "for node_id, domain, count in top_70:\n",
        "    print(f\"{node_id}\\t{domain}\\t{count}\")"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Document ID, Domain Name, In-Link Count\n",
            "185524\tedu.mit.web\t4388\n",
            "278032\tedu.stanford\t4021\n",
            "244433\tedu.purdue.english.owl\t3531\n",
            "140443\tedu.indiana\t3339\n",
            "237176\tedu.princeton\t3251\n",
            "64587\tedu.columbia\t3123\n",
            "465503\tedu.yale\t2804\n",
            "418623\tedu.utexas\t2622\n",
            "383763\tedu.unc\t2592\n",
            "197698\tedu.nap\t2494\n",
            "439637\tedu.washington\t2291\n",
            "373442\tedu.umich\t2281\n",
            "440674\tedu.washington.depts\t2276\n",
            "148945\tedu.jhu.muse\t2255\n",
            "60975\tedu.colorado\t2232\n",
            "449738\tedu.wisc\t2230\n",
            "38320\tedu.bu\t2205\n",
            "83572\tedu.dartmouth\t1965\n",
            "408380\tedu.usc\t1952\n",
            "178879\tedu.mit\t1946\n",
            "27307\tedu.berkeley\t1908\n",
            "233405\tedu.pitt\t1857\n",
            "191069\tedu.msu\t1810\n",
            "326371\tedu.uchicago.press\t1763\n",
            "136464\tedu.illinois\t1753\n",
            "93874\tedu.educause\t1741\n",
            "56979\tedu.cmu.cs\t1730\n",
            "199032\tedu.ncsu\t1709\n",
            "36294\tedu.brown\t1702\n",
            "202182\tedu.nd\t1689\n",
            "68675\tedu.cornell\t1685\n",
            "71095\tedu.cornell.law\t1646\n",
            "183214\tedu.mit.mitpress\t1644\n",
            "215627\tedu.nyu\t1625\n",
            "56538\tedu.cmu\t1583\n",
            "239378\tedu.psu\t1541\n",
            "350412\tedu.ufl\t1533\n",
            "120819\tedu.harvard\t1529\n",
            "270369\tedu.si\t1513\n",
            "107916\tedu.gatech\t1500\n",
            "365396\tedu.uky\t1497\n",
            "337138\tedu.ucop\t1482\n",
            "358246\tedu.uic\t1472\n",
            "382564\tedu.umn.www1\t1470\n",
            "403069\tedu.upenn\t1464\n",
            "293521\tedu.tamu\t1452\n",
            "284517\tedu.stanford.web\t1451\n",
            "256613\tedu.rutgers\t1440\n",
            "367316\tedu.umass\t1430\n",
            "457936\tedu.wsu\t1419\n",
            "36154\tedu.brookings\t1388\n",
            "323918\tedu.uchicago\t1377\n",
            "440902\tedu.washington.faculty\t1363\n",
            "282555\tedu.stanford.plato\t1353\n",
            "392894\tedu.universityofcalifornia\t1353\n",
            "329686\tedu.ucla\t1347\n",
            "317828\tedu.ucdavis\t1343\n",
            "354337\tedu.uga\t1339\n",
            "225417\tedu.osu\t1322\n",
            "393138\tedu.unl\t1319\n",
            "14945\tedu.arizona\t1308\n",
            "429488\tedu.vanderbilt\t1308\n",
            "377474\tedu.umich.www-personal\t1302\n",
            "342997\tedu.ucsd\t1295\n",
            "360674\tedu.uiowa\t1285\n",
            "378163\tedu.umn\t1285\n",
            "118806\tedu.gwu\t1280\n",
            "621\tedu.academia\t1272\n",
            "334739\tedu.uconn\t1268\n",
            "89455\tedu.duke\t1263\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5uSlQEtmPTTA"
      },
      "source": [
        "Then, use the PageRank values compute by your second implementation. Note that some websites will have both a high in-link count and PageRank."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nwcci2kdPlMR",
        "outputId": "3577e5ad-71a6-4ea7-b710-270e94104536",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# TODO: List the document ID, domain name, and PageRank of the 70 websites with the highest PageRank.\n",
        "pr_info = [(node_id, domain, PR[node_id]) for node_id, domain in nodes]\n",
        "\n",
        "# Sort the list by PageRank\n",
        "top_70_pr = sorted(pr_info, key=lambda x: x[2], reverse=True)[:70]\n",
        "\n",
        "print(\"Document ID, Domain Name, PageRank\")\n",
        "for node_id, domain, pr_val in top_70_pr:\n",
        "    print(f\"{node_id}\\t{domain}\\t{pr_val:.6f}\")"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Document ID, Domain Name, PageRank\n",
            "185524\tedu.mit.web\t0.000928\n",
            "465503\tedu.yale\t0.000701\n",
            "318278\tedu.ucdavis.cas\t0.000642\n",
            "278032\tedu.stanford\t0.000594\n",
            "136464\tedu.illinois\t0.000580\n",
            "319795\tedu.ucdavis.ice.code\t0.000547\n",
            "237176\tedu.princeton\t0.000502\n",
            "284517\tedu.stanford.web\t0.000475\n",
            "383763\tedu.unc\t0.000472\n",
            "64587\tedu.columbia\t0.000447\n",
            "449738\tedu.wisc\t0.000436\n",
            "60975\tedu.colorado\t0.000432\n",
            "346969\tedu.ucsf\t0.000430\n",
            "140443\tedu.indiana\t0.000430\n",
            "42502\tedu.byu.cas\t0.000418\n",
            "334739\tedu.uconn\t0.000413\n",
            "14945\tedu.arizona\t0.000409\n",
            "244433\tedu.purdue.english.owl\t0.000403\n",
            "373442\tedu.umich\t0.000402\n",
            "439637\tedu.washington\t0.000398\n",
            "408380\tedu.usc\t0.000391\n",
            "191069\tedu.msu\t0.000391\n",
            "281817\tedu.stanford.med\t0.000391\n",
            "418623\tedu.utexas\t0.000382\n",
            "239378\tedu.psu\t0.000379\n",
            "68675\tedu.cornell\t0.000374\n",
            "342997\tedu.ucsd\t0.000358\n",
            "153823\tedu.kit\t0.000358\n",
            "293521\tedu.tamu\t0.000357\n",
            "197698\tedu.nap\t0.000353\n",
            "337138\tedu.ucop\t0.000346\n",
            "233405\tedu.pitt\t0.000344\n",
            "307291\tedu.ttu.depts\t0.000340\n",
            "323918\tedu.uchicago\t0.000337\n",
            "225417\tedu.osu\t0.000335\n",
            "126385\tedu.harvard.pin1\t0.000331\n",
            "317828\tedu.ucdavis\t0.000327\n",
            "459977\tedu.wustl\t0.000327\n",
            "358246\tedu.uic\t0.000325\n",
            "256613\tedu.rutgers\t0.000321\n",
            "440674\tedu.washington.depts\t0.000317\n",
            "120819\tedu.harvard\t0.000312\n",
            "71095\tedu.cornell.law\t0.000310\n",
            "392894\tedu.universityofcalifornia\t0.000309\n",
            "415321\tedu.utah\t0.000309\n",
            "227645\tedu.ou\t0.000308\n",
            "230724\tedu.paulmitchell\t0.000303\n",
            "107916\tedu.gatech\t0.000303\n",
            "202182\tedu.nd\t0.000298\n",
            "27307\tedu.berkeley\t0.000294\n",
            "38320\tedu.bu\t0.000294\n",
            "56538\tedu.cmu\t0.000290\n",
            "310453\tedu.ua\t0.000289\n",
            "466684\tedu.yale.its.secure\t0.000287\n",
            "369944\tedu.umd\t0.000283\n",
            "178879\tedu.mit\t0.000280\n",
            "148945\tedu.jhu.muse\t0.000276\n",
            "144435\tedu.iu\t0.000274\n",
            "416152\tedu.utah.go\t0.000271\n",
            "46450\tedu.caltech\t0.000270\n",
            "62566\tedu.colostate\t0.000266\n",
            "341211\tedu.ucsc\t0.000265\n",
            "199032\tedu.ncsu\t0.000261\n",
            "42252\tedu.byu\t0.000260\n",
            "329686\tedu.ucla\t0.000256\n",
            "360674\tedu.uiowa\t0.000255\n",
            "403069\tedu.upenn\t0.000254\n",
            "36294\tedu.brown\t0.000250\n",
            "176740\tedu.missouri\t0.000248\n",
            "8451\tedu.acenet\t0.000247\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SxODBxL_Pyy2"
      },
      "source": [
        "Finally, compute some summary statistics on this dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oD4bq6AyQIsU",
        "outputId": "e8636ad9-aedf-495b-9930-c86762137c07",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# TODO: Compute:\n",
        "# - the proportion of websites with no in-links (i.e., source nodes);\n",
        "\n",
        "# - the proportion of websites with no out-links (i.e., sink nodes);\n",
        "\n",
        "# - the proportion of websites whose PageRank is higher than the initial uniform distribution.\n",
        "\n",
        "num_nodes = len(nodes)\n",
        "\n",
        "# Compute in-link counts for each node.\n",
        "in_link_counts = {node_id: 0 for node_id, _ in nodes}\n",
        "for src, dst in edges:\n",
        "    in_link_counts[dst] += 1\n",
        "\n",
        "# Proportion of websites with no in-links\n",
        "num_no_in_links = sum(1 for node_id, _ in nodes if in_link_counts[node_id] == 0)\n",
        "prop_no_in_links = num_no_in_links / num_nodes\n",
        "\n",
        "# Compute out-degree for each node.\n",
        "out_degree = {node_id: 0 for node_id, _ in nodes}\n",
        "for src, dst in edges:\n",
        "    out_degree[src] += 1\n",
        "\n",
        "# Proportion of websites with no out-links\n",
        "num_no_out_links = sum(1 for node_id, _ in nodes if out_degree[node_id] == 0)\n",
        "prop_no_out_links = num_no_out_links / num_nodes\n",
        "\n",
        "# Proportion of websites whose PageRank is higher than the initial uniform distribution.\n",
        "uniform_value = 1 / num_nodes\n",
        "num_above_uniform = sum(1 for node_id, _ in nodes if PR[node_id] > uniform_value)\n",
        "prop_above_uniform = num_above_uniform / num_nodes\n",
        "\n",
        "print(\"Proportion of websites with no in-links (source nodes):\", prop_no_in_links)\n",
        "print(\"Proportion of websites with no out-links (sink nodes):\", prop_no_out_links)\n",
        "print(\"Proportion of websites with PageRank higher than the uniform value:\", prop_above_uniform)\n"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Proportion of websites with no in-links (source nodes): 0.26153633041013563\n",
            "Proportion of websites with no out-links (sink nodes): 0.6106641661427643\n",
            "Proportion of websites with PageRank higher than the uniform value: 0.15514614212494807\n"
          ]
        }
      ]
    }
  ]
}